{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5e5929",
   "metadata": {},
   "source": [
    "# Image Semantic Segmentation using Pretrained model - FCN8-VGG16\n",
    "\n",
    "Semantic Segmentation models has two phases in their architecture: a feature extraction phase and a Dense phase.\n",
    "The feature extraction phase is generally composed of convolution and polling layers. Through these, we estimate many filters weights through numerous layers to extract as many feature as possible. We end up with a very deep NN and a good representation of features in a smaller space. And then by adding Dense layer like the Fully connected Dense Neural Networks(here with 8 layers), we not only flatten those shrinked featuress vectors, but we add an upsampling phase that helps in some ways to adapt and update the featurization phase. We end up having a good representation of the model.\n",
    "\n",
    "Here we followed thse steps in our way of training our model: \n",
    "\n",
    "- **READING DATA**: we uploaded our data using a colab pro account with 25 GB of memory. The colab pro account really worh it. We encountered less disconnections and more memory usage. 25 GB is not enough, but we manage to. deal with it by re-assigning our data variable. Good trick though. We split our data with 4000 samples for training, 500 for validating and 500 for testing.\n",
    "\n",
    "- **SEGMENT GENERATION**: we are recommended to only use 8 categories. For that we build a function that helps us gnerate new segments, by association some of the former ones. It is important to say that is only done on mask images and not on input images.\n",
    "\n",
    "- **DATA AUGMENTATION**: as big fan of tensorflow, we wanted to use tensorflow ImageDataGeneration library, but it doesn't give us a hand or let's us see our generated files (we could save the generated files, but not efficient). And often we ended up have predictions that were not exploitatble. For taht reason end up using ALBUMENTIONS. A very efficient library that just double your data, by transforming it efficiently. We used horizontal flip, a little brightness change, and 10 degree rotation(just an inclinason of the image). \n",
    "\n",
    "- **TRAINING**: 50 epochs training using ADAM optimizer and early stopping based on the validattion loss and patience of 10 epochs. The model choose 5th epochs as the best fit.  \n",
    "\n",
    "- **PREDICTION**: The prediction came naturally by imitating the batching process of the training set on the testing set. We ended up using a batch equal 1 in Training since the compute can handle it. And we did that  after having problem in return prediction value from a the servie gateway. Because with a batch size of 32, 32 images has to be scored at once, na dthey have to pass through the API geteway. And therefore, we had to increase the API gateway, 2GB of memory was not enough. For that we just decided to decrease then batch size to one and let the model to pass the whole dataset at each epoch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9f235f8f",
   "metadata": {
    "id": "9f235f8f"
   },
   "outputs": [],
   "source": [
    "# LIBS\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import Conv2DTranspose\n",
    "from tensorflow.keras.layers import concatenate\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import  EarlyStopping\n",
    "\n",
    "import imageio\n",
    "import os\n",
    "import seaborn as sns\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_7_9XdxnF6vO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7_9XdxnF6vO",
    "outputId": "95f84efb-ce68-4613-8762-fb1d3d4c1d35"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NXErJKY6F6y4",
   "metadata": {
    "id": "NXErJKY6F6y4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = 'drive/MyDrive/AI_LAB/gtFine.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rmZboZu3Gps9",
   "metadata": {
    "id": "rmZboZu3Gps9"
   },
   "outputs": [],
   "source": [
    "local_zip = 'drive/MyDrive/AI_LAB/utils.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a395b165",
   "metadata": {
    "id": "a395b165"
   },
   "outputs": [],
   "source": [
    "# UTILS \n",
    "\n",
    "from utils_fcn_vgg_model import *\n",
    "from utils_funct_vgg import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2403216f",
   "metadata": {},
   "source": [
    "# READING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7f3ab163",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = './gtFine/'\n",
    "train_path_image='train_images/'\n",
    "train_path_mask='train_masks/'\n",
    "\n",
    "val_path_image='val_images/'\n",
    "val_path_mask='val_masks/'\n",
    "\n",
    "test_path_image = 'test_images/'\n",
    "test_path_mask = 'test_masks/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a57c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_list, train_mask_list  = getFilesPathsList(main_path, train_path_image, train_path_mask )\n",
    "\n",
    "\n",
    "val_image_list, val_mask_list = getFilesPathsList(main_path, val_path_image, val_path_mask )\n",
    "\n",
    "\n",
    "test_image_list , test_mask_list  = getFilesPathsList(main_path, test_path_image, test_path_mask)\n",
    "\n",
    "\n",
    "# add 1025 images files list to the train set from test sets\n",
    "train_image_list , test_image_list  = train_image_list + test_image_list[:1025] , test_image_list[1025:]\n",
    "train_mask_list , test_mask_list  = train_mask_list + test_mask_list[:1025] , test_mask_list[1025:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efece8f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2975, 2975)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_image_list) , len(train_mask_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6897208",
   "metadata": {},
   "source": [
    "for i, j, f in zip(test_image_list[:1025], test_mask_list[:1025], range(len(test_image_list[:1025]))):\n",
    "    #print(i, sorted(os.listdir(test_path_image))[f] )\n",
    "    shutil.copyfile(i, train_path_image+sorted(os.listdir(test_path_image))[f] )\n",
    "    shutil.copyfile(j, train_path_mask+sorted(os.listdir(test_path_mask))[f] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Oc6UM7ZloDct",
   "metadata": {
    "id": "Oc6UM7ZloDct"
   },
   "outputs": [],
   "source": [
    "# https://cs230.stanford.edu/blog/datapipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ve2-6vGJ3rjX",
   "metadata": {
    "id": "ve2-6vGJ3rjX"
   },
   "outputs": [],
   "source": [
    "# READ FROM RAW\n",
    "val_image, val_mask = readDataImages(val_image_list, \n",
    "                             val_mask_list)\n",
    "\n",
    "test_image, test_mask = readDataImages(test_image_list, \n",
    "                             test_mask_list)\n",
    "\n",
    "train_image, train_mask = readDataImages(train_image_list, \n",
    "                             train_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "oXOnR5Y_3rm-",
   "metadata": {
    "id": "oXOnR5Y_3rm-"
   },
   "outputs": [],
   "source": [
    "# SEG GEN\n",
    "val_image, val_mask = stackDataSets(val_image, val_mask)\n",
    "\n",
    "train_image, train_mask= stackDataSets(train_image, train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a84561",
   "metadata": {
    "id": "62a84561"
   },
   "outputs": [],
   "source": [
    "# AUGMENT AND MERGE \n",
    "# OPTION TO AUG OR NOT\n",
    "\n",
    "val_image, val_mask = augConcat(val_image.numpy(), val_mask.numpy()) \n",
    "\n",
    "train_image, train_mask = augConcat(train_image.numpy(), train_mask.numpy() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AJ6g9eDo5b2M",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AJ6g9eDo5b2M",
    "outputId": "7aec438c-de83-4065-d677-59367f89b957"
   },
   "outputs": [],
   "source": [
    "train_image.shape , val_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ITeK5Rhv7ngU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITeK5Rhv7ngU",
    "outputId": "8c5196a2-4221-47dd-f515-7dc0df38aa10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['void', 'flat', 'construction', 'object', 'nature', 'sky', 'human', 'vehicle']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=[x for x in cats.keys()]\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ShgUGVMotxqJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShgUGVMotxqJ",
    "outputId": "7742e606-2ad2-4eb8-8c6a-a4286d508e1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([500, 224, 224, 3]), TensorShape([500, 224, 224, 1]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image.shape, val_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "yeGpAM04txm-",
   "metadata": {
    "id": "yeGpAM04txm-"
   },
   "outputs": [],
   "source": [
    "# Convert Numpy data to DataSets for training (a choice for convenience)\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val_image, val_mask ))\n",
    "\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_image, train_mask ))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a76cfe9",
   "metadata": {
    "id": "Mh7q-r8guahP"
   },
   "source": [
    "\n",
    "val_dataset=val_dataset.map(mask8)\n",
    "\n",
    "train_dataset=train_dataset.map(mask8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cb154",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dIUu291AN6lO",
   "metadata": {
    "id": "dIUu291AN6lO"
   },
   "outputs": [],
   "source": [
    "# LOAD WEIGHT IF NOT\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras import layers, Model\n",
    "#!wget https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "#from utils_fcn_vgg_model import *\n",
    "\n",
    "model_vgg_fcn = segmentation_model(n_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GuENnVemOqhl",
   "metadata": {
    "id": "GuENnVemOqhl"
   },
   "outputs": [],
   "source": [
    "#model_vgg_fcn.summary()\n",
    "\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=1E-2,\n",
    "                              momentum=0.9, \n",
    "                              nesterov=True)\n",
    "\n",
    "model_vgg_fcn.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=sgd,\n",
    "                      metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e72eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset1=train_dataset.take(2000)\n",
    "val_dataset1=val_dataset.take(300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_V2-oLYw0K3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_V2-oLYw0K3c",
    "outputId": "3ddb71db-1632-49f1-ad09-9692a4d26b64"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "VAL_SUBSPLITS = 5\n",
    "BUFFER_SIZE = 250\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#train_data_unet1 = train_data_unet.batch(BATCH_SIZE)\n",
    "#val_data_unet1 = val_data_unet.batch(BATCH_SIZE)\n",
    "\n",
    "train_data_vgg = train_dataset1.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "val_data_vgg = val_dataset1.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data_vgg.element_spec)\n",
    "\n",
    "model_history = model_vgg_fcn.fit(train_data_vgg, \n",
    "          epochs=EPOCHS, \n",
    "          validation_data=val_data_vgg, \n",
    "          verbose=2,\n",
    "          callbacks=[EarlyStopping(\n",
    "              patience=3,\n",
    "              min_delta=0.05,\n",
    "              baseline=0.8,\n",
    "              mode='min',\n",
    "              monitor='val_loss',\n",
    "              restore_best_weights=True,\n",
    "              verbose=1)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7f897",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in val_data_vgg.take(1):\n",
    "    y_true_img = i\n",
    "    y_true_seg = j\n",
    "    \n",
    "print(y_true_img.shape,y_true_seg.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c909dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a60199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction\n",
    "# get the model prediction\n",
    "results = model_vgg_fcn.predict(y_true_img)\n",
    "                        #, steps=validation_steps)\n",
    "\n",
    "# for each pixel, get the slice number which has the highest probability\n",
    "results = np.argmax(results, axis=3)\n",
    "\n",
    "# collapse the 8D to 2D plane for true values\n",
    "y_true_seg = np.argmax(y_true_seg, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4185e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape , results[0].shape, np.max(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_seg.shape , y_true_seg[0].shape, np.max(y_true_seg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec430332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate a list that contains one color for each class\n",
    "#colors = sns.color_palette(None, len(cats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c586189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_slider=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the output and metrics\n",
    "colors = sns.color_palette(None, 8)\n",
    "\n",
    "# compute metrics\n",
    "iou, dice_score = compute_metrics(y_true_seg[integer_slider], \n",
    "                                  results[integer_slider], n_classes=8) \n",
    "\n",
    "show_predictions(y_true_img[integer_slider], \n",
    "                 [results[integer_slider], y_true_seg[integer_slider]],\n",
    "                 [\"Image\", \"Predicted Mask\", \"True Mask\"], \n",
    "                 iou, \n",
    "                 dice_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "P8_AUTONOMOUS_DRIVING_CAR_FCNVGG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
